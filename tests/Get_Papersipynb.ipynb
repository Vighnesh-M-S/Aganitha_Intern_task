{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "we1OaYxZWJTh"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "# Function to fetch PubMed paper IDs based on a search query\n",
        "def fetch_papers(query: str) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Fetches a list of PubMed paper IDs for the given query.\n",
        "    \n",
        "    Parameters:\n",
        "        query (str): The search query to fetch papers for.\n",
        "\n",
        "    Returns:\n",
        "        List[Dict]: A list of dictionaries, each containing a paper ID.\n",
        "    \"\"\"\n",
        "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
        "    params = {\n",
        "        \"db\": \"pubmed\",          # Database to search in\n",
        "        \"term\": query,           # Search query\n",
        "        \"retmode\": \"json\",       # Response format\n",
        "        \"retmax\": 100            # Max number of results to return\n",
        "    }\n",
        "\n",
        "    # Make a GET request to the PubMed API\n",
        "    response = requests.get(base_url, params=params)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f\"Failed to fetch data from PubMed API. Status code: {response.status_code}\")\n",
        "\n",
        "    try:\n",
        "        # Parse the JSON response\n",
        "        data = response.json()\n",
        "        # Extract the list of paper IDs\n",
        "        id_list = data.get(\"esearchresult\", {}).get(\"idlist\", [])\n",
        "        return [{\"id\": id} for id in id_list]\n",
        "    except ValueError as e:\n",
        "        raise Exception(f\"Failed to parse JSON: {e}\")\n",
        "\n",
        "# Function to fetch detailed metadata for a list of PubMed paper IDs\n",
        "def fetch_paper_details(paper_ids: List[str]) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Fetches detailed information for a list of PubMed paper IDs.\n",
        "    \n",
        "    Parameters:\n",
        "        paper_ids (List[str]): A list of PubMed paper IDs.\n",
        "\n",
        "    Returns:\n",
        "        List[Dict]: A list of dictionaries, each containing metadata for a paper.\n",
        "    \"\"\"\n",
        "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi\"\n",
        "    params = {\n",
        "        \"db\": \"pubmed\",              # Database to fetch details from\n",
        "        \"id\": \",\".join(paper_ids),   # Comma-separated list of paper IDs\n",
        "        \"retmode\": \"json\"            # Response format\n",
        "    }\n",
        "\n",
        "    # Make a GET request to fetch paper details\n",
        "    response = requests.get(base_url, params=params)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f\"Failed to fetch paper details. Status code: {response.status_code}\")\n",
        "\n",
        "    try:\n",
        "        # Parse the JSON response\n",
        "        data = response.json()\n",
        "        return [\n",
        "            {\n",
        "                \"id\": paper_id,\n",
        "                \"title\": summary.get(\"title\", \"\"),        # Extract paper title\n",
        "                \"authors\": summary.get(\"authors\", []),   # Extract list of authors\n",
        "                \"pub_date\": summary.get(\"pubdate\", \"\")   # Extract publication date\n",
        "            }\n",
        "            for paper_id, summary in data.get(\"result\", {}).items()\n",
        "            if paper_id != \"uids\"  # Skip the 'uids' key, which is metadata\n",
        "        ]\n",
        "    except ValueError as e:\n",
        "        raise Exception(f\"Failed to parse JSON: {e}\")\n",
        "\n",
        "# Function to filter non-academic authors from the paper metadata\n",
        "def filter_non_academic_authors(papers: List[Dict]) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Filters out non-academic authors based on their affiliations.\n",
        "    \n",
        "    Parameters:\n",
        "        papers (List[Dict]): A list of dictionaries, each containing paper metadata.\n",
        "\n",
        "    Returns:\n",
        "        List[Dict]: A list of dictionaries with filtered metadata for papers \n",
        "                    with non-academic authors.\n",
        "    \"\"\"\n",
        "    filtered_papers = []\n",
        "    for paper in papers:\n",
        "        authors = paper.get('authors', [])  # Get the list of authors\n",
        "        non_academic_authors = []           # List to store non-academic authors\n",
        "        company_affiliations = []           # List to store company affiliations\n",
        "\n",
        "        for author in authors:\n",
        "            # Use .get() to handle missing keys gracefully\n",
        "            affiliation = author.get('affiliation', '').lower()\n",
        "            if \"university\" not in affiliation and \"lab\" not in affiliation:\n",
        "                # Add non-academic authors and their affiliations\n",
        "                non_academic_authors.append(author.get('name', 'Unknown Author'))\n",
        "                company_affiliations.append(author.get('affiliation', 'Unknown Affiliation'))\n",
        "\n",
        "        if non_academic_authors:\n",
        "            # Add the filtered paper details to the result list\n",
        "            filtered_papers.append({\n",
        "                \"PubmedID\": paper['id'],                        # Paper ID\n",
        "                \"Title\": paper['title'],                        # Paper title\n",
        "                \"Publication Date\": paper['pub_date'],          # Publication date\n",
        "                \"Non-academic Author(s)\": \", \".join(non_academic_authors),\n",
        "                \"Company Affiliation(s)\": \", \".join(company_affiliations),\n",
        "                \"Corresponding Author Email\": paper.get('corresponding_author_email', 'Unknown Email')\n",
        "            })\n",
        "\n",
        "    return filtered_papers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjyL_aL_WK6b",
        "outputId": "47457236-d68c-487f-ce19-6907e2b6f86f"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import pandas as pd\n",
        "# from get_papers.fetch_papers import fetch_papers, filter_non_academic_authors, fetch_paper_details\n",
        "\n",
        "def main():\n",
        "    query = input(\"Enter your search query for PubMed: \")\n",
        "    file_output = input(\"Enter the output filename for CSV (leave blank to skip): \")\n",
        "    debug = input(\"Enable debug output? (yes/no): \").strip().lower() == 'yes'\n",
        "\n",
        "    if debug:\n",
        "        print(f\"Fetching papers for query: {query}\")\n",
        "\n",
        "    # Fetch paper IDs using the provided query\n",
        "    paper_ids = fetch_papers(query)\n",
        "    if debug:\n",
        "        print(f\"Fetched {len(paper_ids)} paper IDs\")\n",
        "\n",
        "    # Fetch detailed paper information\n",
        "    paper_details = fetch_paper_details([paper[\"id\"] for paper in paper_ids])\n",
        "    if debug:\n",
        "        print(f\"Fetched details for {len(paper_details)} papers\")\n",
        "\n",
        "    # Filter out non-academic authors\n",
        "    filtered_papers = filter_non_academic_authors(paper_details)\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(filtered_papers)\n",
        "\n",
        "    if file_output:\n",
        "        df.to_csv(file_output, index=False)\n",
        "        print(f\"Results saved to {file_output}\")\n",
        "    else:\n",
        "        print(df)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Get Papers List(Aganiths_Intern_task)\n",
        "\n",
        "This project fetches research papers from PubMed based on a query, filters out non-academic authors, and generates a CSV file with relevant details. \n",
        "\n",
        "Git Hub Repo : https://github.com/Vighnesh-M-S/Aganitha_Intern_task"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
